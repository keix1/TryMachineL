# -*- coding: utf-8 -*-

# http://qiita.com/yoshizaki_kkgk/items/bfe559d1bdd434be03ed　の内容

# 数値計算関連
import math
import random
import numpy as np
import matplotlib.pyplot as plt
# chainer
from chainer import Chain, Variable
import chainer.functions as F
import chainer.links as L
from chainer import optimizers
from MyChain import MyChain

# 乱数のシードを固定
random.seed(1)

# 標本データの生成
#   真の関数としてsin関数を
x, y = [], []
for i in np.linspace(-3,3,100):
    x.append([i])
    y.append([math.sin(i)])  # 真の関数
# chainerの変数として再度宣言
x = Variable(np.array(x, dtype=np.float32))
y = Variable(np.array(y, dtype=np.float32))

# NNモデルを宣言
model = MyChain()

# 損失関数の計算
#   損失関数には自乗誤差(MSE)を使用
def forward(x, y, model):
    t = model.predict(x)
    loss = F.mean_squared_error(t, y)
    return loss

# chainerのoptimizer
#   最適化のアルゴリズムには Adam を使用
optimizer = optimizers.Adam()
# modelのパラメータをoptimizerに渡す
optimizer.setup(model)

# パラメータの学習を繰り返す
for i in range(0,1000):
    loss = forward(x, y, model)
    print(loss.data)  # 現状のMSEを表示
    optimizer.update(forward, x, y, model)

# プロット
t = model.predict(x)
plt.plot(x.data, y.data)
plt.scatter(x.data, t.data)
plt.grid(which='major',color='gray',linestyle='-')
plt.ylim(-1.5, 1.5)
plt.xlim(-4, 4)
plt.show()

